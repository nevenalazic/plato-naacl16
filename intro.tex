\section{Introduction}
\label{sec:intro}

Named entity resolution and disambiguation (NERD) is the task of mapping each mention of an entity in a document to the corresponding record in a knowledge base (KB) \cite{BunescuP06,Cucerzan07,KulkarniSRC09,Dredze2010,Hoffart2011,Hachey2013130}.  
 %with numerous applications \cite{Gabrilovich2007,Lin2012,Kwiatkowski2011,finin2009Coreference,mayfield2009cross}. 
%Key applications 
%are to information extraction  and grounded semantic parsing. %text classification~\cite{Gabrilovich2007}, 
%information extraction~\cite{Lin2012} and grounded semantic parsing~\cite{Kwiatkowski2011}. 
%It can also provide a valuable signal to other language-processing tasks, including part-of-speech tagging, parsing, and coreference resolution~\cite{finin2009Coreference,mayfield2009cross}.
%Entity resolution
This is a challenging problem, as referring expressions are often ambiguous on their own, and can only be resolved given appropriate context. For example, the mention \qtext{Beirut} may refer to the capital of Lebanon, to the indie band from New Mexico, or to a drinking game. Names may also refer to entities that are not in the KB, a problem known as \emph{{\NIL} detection}. 
Entity resolution applications include numerous language-processing tasks  \cite{Gabrilovich2007,Lin2012,finin2009Coreference,mayfield2009cross}. \todo{rephrase}%Kwiatkowski2011

Systems for entity resolution typically consist of a \emph{mention model}, a \emph{context model}, and a \emph{coherence model}.\todo{refs} The mention model establishes a link between each entity and its textual representations, also called aliases or surface forms. The context model helps resolve an ambiguous phrase using textual features extracted from the surrounding context, such as the enclosing sentence and salient noun phrases in the document. The coherence model, which is our focus in this work, encourages all mentions to resolve to entities that are related to each. This relation may defined via
the KB, web links or other resources. 

Coherence models are often specified via a graph whose vertices are candidate entities for all mentions, and whose edges express relations between candidate entities for these mentions.\footnote{An exception to this framework are topic models in which a topic may generate both entities and words, e.g. \cite{kataria2011,HanS12,houlsby2014scalable}.}  Vertex weights correspond to prior scores for candidate entities, while edge weights correspond to some notion of relation strength. There exist different ways to leverage such a graph for inference purposes. Broadly speaking, all methods define a score function over whole document disambiguation, and see a labeling that maximizes this score. However, since maximizing the score is typically intractable, various approximations and heuristics are employed.\todo{refs}

Here we propose to enhance coherence models by introducing a multi-focal attention mechanism. Attention has recently been used with considerable empirical success in tasks such as translation \cite{bahdanau2014neural} and image caption generation \cite{xu2015show}. For NERD, we argue that attention is desirable since  aggregating support for an entity label over the whole document may dilute the evidence for non-salient entities. Instead, we propose a model where each mention {\em chooses} a small set of mentions to attend to, and then uses those to calculate its coherence score. 

We show how such an approach can result in a simple inference algorithm, and how the model parameters can be  learned from data. We also
provide a smoothed version of the attention function, that generalizes the soft-max function used in single-focus attention schemes. 

Finally, we evaluate our model by using a context model from the recently introduced Plato system \cite{Lazic2015} (note that Plato does not use a coherence model). This leads to performance improvements on three benchmarks, and yields new state-of-the-art results on the TAC KBP 2010-2012 datasets, and the CoNLL 2003 dataset.\todo{be more specific}

Our contributions thus consist of defining a novel multi-focal attention based model, where inference is efficient, and applying it successfully to an entity linking system. We note that our model can be easily applied to other structured prediction problems in NLP.\todo{Consider expanding this}
%Our premise is that this may also hold for entity relations: aggregating support for an entity label over the whole document may dilute the evidence for non-salient entities. We explore two new approaches to coherence that focus on a \emph{limited number} of relations for each candidate, rather than relations to all other entities. 

\input{fig_graph}
%  Accordingly, we propose to choose the label for each mention based on the best support from a \emph{limited number} of other mentions.  In other words,  each mention is labeled by (tractable) inference in a star graph, but one where most edges are (dynamically) ignored.
\comment{
\subsection{Our contributions}
\label{sec:intro:our}


In the first approach, which we name \emph{single link}, we formulate inference as finding the highest-weight subgraph in which each candidate has a directed edge to \emph{at most} one other candidate. This can roughly be seen as maximizing over relations as opposed to averaging. In this model we perform inference using max-sum belief propagation \cite{Kschischang2001}.

%; however, it is slightly more computationally involved since an edge between two entities is allowed only if the corresponding mentions resolve to them. 
%We specify the objective and constraints using binary edge-indicator variables, and find the maximum-a-posteriori solution using the max-sum algorithm \cite{Kschischang2001}. 
Our

In the second \emph{attention} model, we allow each mention to have up to $K$ relations to other mentions. In this case, inference is tractable, and we also learn mention and edge scores from a small set of simple features.   %In other words,  each mention is labeled by (tractable) inference in a star graph, but one where most edges are (dynamically) ignored.

We use these coherence models to re-rank candidates generated by Plato \cite{Lazic2015}, a recent entity resolution system that has highly competitive performance and does not include a coherence component. This leads to performance improvements on three benchmarks, and yields new state-of-the-art results on the TAC KBP 2011 and 2012 datasets.
}
\todo{paper layout}


