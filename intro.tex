\section{Introduction}
\label{sec:intro}

Entity resolution is the task of mapping each mention of an entity in a document to the corresponding record in a knowledge base (KB) \cite{BunescuP06,Cucerzan07,Dredze2010,Hachey2013130}.  
 %with numerous applications \cite{Gabrilovich2007,Lin2012,Kwiatkowski2011,finin2009Coreference,mayfield2009cross}. 
%Key applications 
%are to information extraction  and grounded semantic parsing. %text classification~\cite{Gabrilovich2007}, 
%information extraction~\cite{Lin2012} and grounded semantic parsing~\cite{Kwiatkowski2011}. 
%It can also provide a valuable signal to other language-processing tasks, including part-of-speech tagging, parsing, and coreference resolution~\cite{finin2009Coreference,mayfield2009cross}.
%Entity resolution
This is a challenging problem, as referring expressions are often ambiguous on their own, and can only be resolved given appropriate context. For example, the mention \qtext{Beirut} may refer to the capital of Lebanon, to the indie band from New Mexico, or to a drinking game. Names may also refer to entities that are not in the KB, a problem known as \emph{{\NIL} detection}. 
Entity resolution applications include numerous language-processing tasks  \cite{Gabrilovich2007,Lin2012,finin2009Coreference,mayfield2009cross}. %Kwiatkowski2011

Systems for entity resolution typically consist of a \emph{mention model}, a \emph{context model}, and a \emph{coherence model}. The mention model establishes a link between each entity and its textual representations, also called aliases or surface forms. The context model helps resolve an ambiguous phrase using textual features extracted from the surrounding context, such as the enclosing sentence and salient noun phrases in the document. The coherence model encourages all mentions to resolve to entities that are related to each other in the KB. 

Coherence models are often specified via a graph whose vertices are candidate entities for all mentions, and whose edges indicate known relations\footnote{An exception to this framework are topic models in which a topic may generate both entities and words, e.g. \cite{HanS12,houlsby2014scalable}.}. Vertex weights correspond to prior scores for candidate entities, while edge weights correspond to some notion of relation strength. There exist different ways to leverage such a graph for disambiguation purposes. Some systems compute an overall ``relatedness'' score for each candidate as the average of adjacent edge weights \cite{Milne2008,Ferragina10}. \newcite{Ratinov11} use relation scores as features in a ranking support vector machine. \newcite{KulkarniSRC09} formulate the task as an integer linear program and find solutions via a convex relaxation, while \newcite{Hoffart2011} extract a dense subgraph from the original graph. More recent systems \cite{Han2011,He13,Alhelbawy14,Pershina2015} use variants of the PageRank algorithm \cite{PageRank} to re-score candidates.  

In this work, we formulate inference as finding the highest-weight subgraph in which each candidate has a directed edge to \emph{at most} one other candidate. This can roughly be seen as maximizing over neighboring edge weights as opposed to averaging; however, it is slightly more computationally involved since an edge between two entities is allowed only if the corresponding mentions resolve to them. We specify the objective and constraints using binary edge-indicator variables, and find the maximum-a-posteriori solution using the max-sum algorithm \cite{Kschischang2001}. TODO: more motivation / rationale.
 
We use our technique to re-score candidates generated by Plato \cite{Lazic2015}, a recent entity resolution system that has highly competitive performance and does not include a coherence component. This leads to performance improvements on three benchmarks, and yields new state-of-the-art results on the TAC KBP 2011 and 2012 datasets.

