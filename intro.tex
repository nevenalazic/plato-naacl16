\section{Introduction}
\label{sec:intro}

Entity resolution (ER) is the task of mapping mentions of entities in
text to corresponding records in a knowledge base (KB)
\cite{BunescuP06,Cucerzan07,KulkarniSRC09,Dredze2010,Hoffart2011,Hachey2013130}.
ER is a challenging problem because mentions are often ambiguous on
their own, and can only be resolved given appropriate context.  For
example, the mention \qtext{Beirut} may refer to the capital of
Lebanon, the band from New Mexico, or a drinking game
(Figure~\ref{fig:ereg}).
Names may also refer to entities that are not in the KB, a problem
 known as \emph{{\NIL} detection}.
% ER can improve text classification \cite{Gabrilovich2007}, information
% extraction \cite{Lin2012}, coreference resolution
% \cite{finin2009Coreference,mayfield2009cross} and other
% language-processing tasks.
%Kwiatkowski2011groundedsemparsing

Most ER systems consist of a \emph{mention model}, a \emph{context
  model}, and a \emph{coherence
  model}~\cite{Milne2008,Cucerzan07,Ratinov11,Hoffart2011,Hachey2013130}.
The mention model associates each entity with its possible textual
representations (also known as aliases or surface forms).  The context
model helps resolve an ambiguous mention using textual features
extracted from the surrounding context. 
%, such as the enclosing sentence and salient noun phrases in the document. 
The coherence model, the focus of this work, encourages all mentions to resolve to
entities that are related to each other.  Relations may be established
via the KB, Web links, embeddings, or other resources.

Coherence models often define an objective function that includes
local and pairwise candidate scores, where the pairwise scores
correspond to some notion of coherence or relation
strength.\footnote{An exception to this framework are topic models in
  which a topic may generate both entities and words, e.g.,
  \cite{kataria2011,HanS12,houlsby2014scalable}.} 
  Support for a candidate is typically aggregated over
relations to all other entities in the document. One problem with this approach is that it may
dilute evidence for entities that are not salient in the document, or
not well-connected in the KB. This is an issue we aim to address.
%Finding an entity
% labeling that maximizes the objective is usually intractable and
% tackled via various approximations, which we discuss in more detail in
% Section~\ref{sec:related}. 

\input{example-beirut}

%The above coherence objectives consider the sum over all pairwise terms. Such
%``all-pairs'' coherence objectives aggregate over salient, well-connected
%entities and less prominent entities that are not so well-connected.
%In effect, all-pairs objectives seek evidence in favor of a candidate
%entity from \emph{all} other mentions in the document, evidence that
%may simply not exist for non-salient entities.  However, valuable
%support in favor of a candidate entity may be provided by a small
%number of entities chosen for other mentions.  Thus, all-pairs
%objectives risk losing these delicate signals.  Our primary goal is to
%fix this problem.

In this work, we introduce a novel coherence model with an attention mechanism, where the 
score for each candidate only depends on a small subset of mentions.
 Attention has recently been
used with considerable empirical success in tasks such as translation
\cite{bahdanau2014neural} and image caption generation
\cite{xu2015show}. We argue that attention is also desirable for
collective ER due to the discussed imbalance in the number of
relations for different entities.

Attention models typically have a single focus, implemented using the
 softmax function. Our model allows each candidate to
 focus on multiple mentions, and to implement it we introduce a 
 novel smooth version of the
 multi-focus attention function, which generalizes soft-max.
%Our model relies on a novel smooth version of the multi-focus
%attention function, which generalizes the single-focus softmax
%function. 
%We use a simple and efficient inference procedure, and show
%how the model parameters can be learned from data.
Our system uses mention and context models similar to  
\newcite{Lazic2015} (which do not use coherence) along with our novel 
multi-focal attention model to 
enforce coherence, leading to significant performance improvements
on CoNLL 2003 \cite{Hoffart2011} and TAC KBP 2010--2012 tasks \cite{TAC2010,TAC2011,TAC2012}.
In particular, we achieve a 20\% relative reduction
in error from \newcite{Chisholm2015} on CoNLL, and a 
22\% error reduction from \newcite{Cucerzan2012} on TAC 2012.
Our contributions thus consist of defining a novel multi-focal
attention model and applying it
successfully to an entity resolution system.


%The rest of the paper is organized as follows: \secref{sec:notation} introduces notation.
%\secref{sec:attention} presents the new multi-focus attention
% model.  \secref{sec:maxsum} discusses a baseline model with
% single focus.  \secref{sec:related} reviews related work.
% \secref{sec:expt} presents experimental results.


%%% Local Variables: ***
%%% mode:latex ***
%%% TeX-master: "main.tex"  ***
%%% tex-main-file: "main.tex"  ***
%%% End: ***
