\noindent
\textbf{Edge features} $\fp$ are set as follows:
\begin{description}
\item[Gold link features:] Denote by $l(y_i,y_j)$ the number of links between $y_i$ and $y_j$ in Wikipedia (in either direction), capped to the value $15$.  We encode $l$ in unary, i.e., introduce a set of $15$ features where the $j^{th}$ feature is set to $1$ if $l(y_i,y_j) = j$, and $0$ otherwise. This is meant to capture non-linear dependencies of coherence on the number of links.
\item[Self-trained link features:] Since Wikipedia links are quite sparse, we augment them by labeling all of Wikipedia with our baseline resolver.  Denote $r(y_i,y_j)$ the number of links in this labeled dataset. Then we add as features $\log{r(y_i,y_j)}$ \todo{$\log(0):=0$? why not $\log(r+1)$?} and a Boolean feature that is 1 iff $r(y_i,y_j)=0$.  We use a log scale here since there are more links than in the gold case. 
\item[Relation features:] Denote by $r(y_i,y_j)$ the number of existing relations between $y_i$ and $y_j$ in FreeBase, capped to the value $15$ (in practice this is usually $0$ or $1$).  We encode $r$ in unary using 15 more features.
\end{description}
We chose this relatively small set of features, so that it can be trained from the small training sets of CoNLL and TAC (both have a few thousand ground truth mentions).
