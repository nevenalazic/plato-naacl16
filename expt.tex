\section{Experimental evaluation}

\subsection{Evaluation data and setup.}
We evaluate our approach on the same three corpora as \newcite{Lazic2015}. The CoNLL dataset ~\cite{Hachey2013130} contains 1,393 articles with about 34K
mentions, and the standard performance metric is mention-averaged accuracy. Most authors report performance on the subset of 231 test-b documents with 4,483 linkable mentions.
The TAC KBP datasets \cite{TAC2011,TAC2012} include 2,226 mentions (2012) and 2,250 mentions (2011), of which roughly half are linkable to the reference KB. The competition evaluation includes $\NIL$ entities;
participants are required to cluster $\NIL$ mentions across documents
so that all mentions of each unknown entity are assigned a unique
identifier. We use the same $\NIL$ cluster labels as Plato. For these datasets, we report in-KB accuracy, overall accuracy (including $\NIL$ mentions), and the competition metric $B^{3+} F_1$. 

\subsection{Local and pairwise scores}
We use the output of Plato \cite{Lazic2015} as our baseline, as well as to generate candidates and local scores $s_i(y_i)$. Plato does not have an explicit coherence model; however, it does capture some coherence information as referrent phrases are included as string features. Plato outputs a posterior distribution $p_i(c)$ over candidates $c$ for each mention $i$, but our models have no probabilistic interpretation.

In the \emph{single link} model, we simply set the local score for mention $i$ and candidate $c$ to $s_i(c) = \ln p_i(c) - \ln (1 - p_i(c))$, so that likely candidates get positive scores. we set the pairwise score between two candidates as $s_{ij}(c, c') = \ln n_{cc'} + 0.7$, where $n_{cc'}$ is the number of outlinks from the Wikipedia page of $c$ to the page of $c'$.  We consider up to three candidates for each mention; if the Plato posterior for the top candidate exceeds $0.9$, we only consider the top candidate.  \hl{TODO: scores in the attention model}



\paragraph{Results.}
We show the performance of the Plato baseline, Plato with coherence, and the best results reported in literature in Tables \ref{table:tac_results} and \ref{table:conll_results}.  The coherence model improves performance on all three datasets, yielding new state-of-the-art results on the TAC KBP datasets. While coherence also leads to improved performance on CoNLL, the overall system does not surpass the state of the art. One reason for this is that the candidate recall of the baseline system (an upper bound on accuracy) is relatively low -- below the accuracy of the system of \cite{Pershina2015}. 


\begin{table*}[ht]
\small
\centering
\begin{tabular}{|l|l|l|c|c|c|}
\hline 
\bf Data & \bf Plato & \bf Model & \bf In-KB & \bf Overall & ${\bf B^{3+}F_1}$ \\ 
& \bf cand. recall &  & \bf accuracy & \bf accuracy & \\ \hline
TAC 2011 & 84.8 & \newcite{Cucerzan2011} &- & 86.8 &  {84.1} \\
&& Plato \cite{Lazic2015} & 79.3 & 86.5 & 84.0 \\
&& Plato with \emph{single lin} & {\bf 81.2} & {\bf 87.0} & {\bf 84.5} \\
&& Plato with \emph{soft attention} & & & \\
\hline
\hline
TAC 2012 & 83.2 &\newcite{Cucerzan2012}  Run 1 & 72.0 & 76.2 & 72.1  \\
&&\newcite{Cucerzan2012} Run 3 & 71.2 & {76.6} & {\bf 73.0} \\
&&Plato \cite{Lazic2015} & {74.2} & {76.6} & 71.2 \\
&&Plato with \emph{single link} & {\bf 75.1} & {\bf 77.3} & {72.2} \\
&& Plato with \emph{soft attention} & & & \\
\hline
\end{tabular}
\caption{ \label{table:tac_results} TAC KBP evaluation results for our model and previous highest-accuracy systems.  }
\end{table*}

\begin{table*}[ht]
\small
\centering
\begin{tabular}{|l|l|l|c|}
\hline
\bf Data & \bf Plato & \bf Model & \bf In-KB  \\ 
& \bf cand. recall &  & \bf accuracy\\ \hline
CoNLL test-b &  & \newcite{Chisholm2015} & {\bf 88.7} \\
& &Plato \cite{Lazic2015} & {86.4}  \\
& &Plato with \emph{single link} & {87.1} \\
& & Plato with \emph{soft attention} & 87.4 \\
\hline
\end{tabular}
\caption{ \label{table:conll_results} CoNLL evaluation results for our model and previous highest-accuracy systems. }
\end{table*}
